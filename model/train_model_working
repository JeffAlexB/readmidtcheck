import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE

# Load your actual dataset here
df = pd.read_csv("../data/sample_data.csv")

# =====================
# FEATURE ENGINEERING
# =====================

le = LabelEncoder()
for col in ['gender', 'primary_diagnosis', 'discharge_to']:
    df[col] = le.fit_transform(df[col].astype(str))

# Age group bins
df['age_group'] = pd.cut(df['age'], bins=[0, 40, 55, 65, 75, 100], labels=[0, 1, 2, 3, 4]).astype(int)

# Stay duration bins
df['stay_group'] = pd.cut(df['days_in_hospital'], bins=[0, 3, 7, 14, 100], labels=[0, 1, 2, 3]).astype(int)

# Comorbidity group
df['comorbidity_group'] = pd.cut(df['comorbidity_score'], bins=[-1, 0, 2, 10], labels=[0, 1, 2]).astype(int)

# Feature interactions
df['age_x_comorbidity'] = df['age'] * df['comorbidity_score']
df['procedures_per_day'] = df['num_procedures'] / (df['days_in_hospital'] + 1e-6)
df['discharged_to_facility'] = df['discharge_to'].isin([1, 2]).astype(int)

# Prepare features and label
X = df.drop(columns=['readmitted', 'age', 'days_in_hospital', 'comorbidity_score'])
y = df['readmitted']

# Split + SMOTE
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# =====================
# BASELINE MODEL COMPARISON
# =====================
from sklearn.metrics import make_scorer, roc_auc_score

models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced'),
    'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)
}

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
baseline_results = {
    name: cross_val_score(model, X_resampled, y_resampled, cv=cv, scoring='roc_auc').mean()
    for name, model in models.items()
}

# Print comparison
print("\n=== Baseline Model Comparison ===")
for model_name, auc in baseline_results.items():
    print(f"{model_name}: ROC AUC = {auc:.4f}")


#
lets put a pin in it for now, but keep those thoughts for when writing the final paper. Considering what we have written so far, how well does it fullfill these requirements?
"-Data → ML model: Use data to develop a machine learning model.
-Accuracy Metric: Provide an appropriate metric or plan for measuring the app’s accuracy.
-Visualizations: Present 3 different pictures; images can code generated or static.
-User Application: Provide a way for the “user” to use the ML model towards solving the problem.
Machine Learning requirements
You must apply machine learning to data.

You are encouraged to use ML libraries. Provided the source code is available to evaluators, any language or library of your choosing is allowed. However, we do recommend and can give better support for Python. The scikit-learn library is an excellent choice; it is diverse, robust, and has many supplementary resources to help you get started.

Visualization requirements
You must have three different images helping describe your project.

The purpose of the visuals is to help the reader understand your project, but little is required other than the three images be unique and related to your project. The images can be generated by the code or inserted statically. The visualizations can describe the data or ML algorithm. They can be the same type describing different data subsets or of different types describing the same data. Examples include pie charts, histograms, scatterplots, confusion matrices, etc.

The visualizations are required to be part of the application. However, sometime this may not be ideal, say when the app is intended to customer facing. So it is allowable to submit the code providing the visualizations separate from the main application code.
acceptable graphs can be: scatterplots, regression lines, confusion matrix, histograms, pie-chart, scatterplot matrix, correlation matric, barplot, lineplots, model explanations, regression and clustering.

User interface requirements
You must provide a user-friendly interface by which the proposed client can use your application to help solve the problem.

Playing the role of the client, the evaluator will follow your user guide in part D of the documentation. To meet this requirement they should be able to do the following:

Run your application (user-friendly). Your application will be considered “user-friendly” if the evaluator successfully executes and uses your application on a Windows 10 machine following your instructions. They can be instructed to download and install necessary dependencies or software.

Use your application to solve the proposed problem as intended (interface). Most often the interface requirement is met by having some way for the user to provide input and receive output. For example, a user provides weather conditions, and the app returns a prediction of popsicle sales. How the interface is implemented, whether it be widgets, uploaded data, or simple console input; is up to you.

At a minimum, the interface must provide means for the user to provide input and receive feedback. Any method by which you can provide instructions is acceptable."
#